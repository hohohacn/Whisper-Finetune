{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1.测试系统Pytroch, GPU, AIshell数据集可用性","metadata":{"_uuid":"d6a40334-a919-4f99-8827-907e1d79deb0","_cell_guid":"18a447ff-7615-41d0-8a0c-9d45ef9a840f","execution":{"iopub.status.busy":"2023-10-25T02:52:39.518800Z","iopub.execute_input":"2023-10-25T02:52:39.519233Z"},"trusted":true}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport torch \nprint(\"GPU status:\"+str(torch.cuda.is_available()) )\nprint(\"pytorch version:\"+torch.__version__)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom IPython.display import Audio\nsamplefile=\"/kaggle/input/aishell-1/speech_asr_aishell_trainsets/speech_asr_aishell_trainsets/wav/train/S0002/BAC009S0002W0122.wav\"\nAudio(samplefile)\n\n! pip install git+https://github.com/openai/whisper.git -q\n\nimport whisper\n\n# small_model = whisper.load_model(\"small\")\n# medium_model = whisper.load_model(\"medium\")\nlarge_model = whisper.load_model(\"large\")\n\n# small_result = small_model.transcribe(samplefile, fp16=False)\n# print(small_result[\"text\"])\n\n# medium_result = medium_model.transcribe(samplefile, fp16=False)\n# print(medium_result[\"text\"])\n\nlarge_result = large_model.transcribe(samplefile, fp16=False)\nprint(large_result[\"text\"])\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"5482cef4-acd9-4259-8fff-3dec28a188db","_cell_guid":"9508d933-2aba-4c09-b062-076d66ad04e8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.下载例子代码\n根据whisper论文，不太强调中文调优，已经训练了足够多的中文音频，所以注释掉aishell代码","metadata":{"_uuid":"78809a6d-c9bc-4c45-886d-a1fcf1a5a76e","_cell_guid":"1d4a4a12-28c6-42a0-8a09-e01f41cfab78","trusted":true}},{"cell_type":"code","source":"import os\nif not os.path.exists(\"/kaggle/working/Whisper-Finetune\"):\n    !git clone https://gitee.com/hohoha/Whisper-Finetune.git /kaggle/working/Whisper-Finetune\n%cd /kaggle/working/Whisper-Finetune\n!git pull \n\nimport shutil\npath = \"/kaggle/working/modelsA\"\nif os.path.exists(path):\n        shutil.rmtree(path)\n        print('删除完成'+path)    \n\n!pip install -r requirements.txt\n# %run ./aishell.py --annotation_text /kaggle/working/aishell --target_dir /kaggle/input/aishell-1 --csv_path /kaggle/input/aishell-adaption/speech_asr_aishell_trainsets_utf8.csv\n","metadata":{"_uuid":"e0f50ffe-8a99-4ad6-9317-f70b8f1d6d2a","_cell_guid":"559d690f-c616-4ed1-b287-03c3da6c24da","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. ctranslate2加速","metadata":{"_uuid":"a903ac47-2235-4e83-8369-d01d270e60b5","_cell_guid":"8eaaea54-3acc-4037-9538-5036910b4a63","trusted":true}},{"cell_type":"code","source":"# !pip install -U whisper-ctranslate2\nimport faster_whisper\n# model = faster_whisper.WhisperModel(\"whisper-large-v2-ct2\")\nmodel_size = \"large-v2\"\nsamplefile=\"/kaggle/input/aishell-1/speech_asr_aishell_trainsets/speech_asr_aishell_trainsets/wav/train/S0002/BAC009S0002W0122.wav\"\n# Run on GPU with FP16\n# model = faster_whisper.WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\",download_root=\"/kaggle/working/models\",local_files_only=False)\n\n# or run on GPU with INT8\n# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n# or run on CPU with INT8\nmodel = faster_whisper.WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\",download_root=\"/kaggle/working/models\",local_files_only=True)\n# model = faster_whisper.WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\",download_root=\"/kaggle/working/models\",local_files_only=False)\n# model = faster_whisper.WhisperModel(\"whisper-large-v2-ct2\")\n\nsegments, info = model.transcribe(samplefile, beam_size=5)\n\nprint(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n\nfor segment in segments:\n    text = segment.text\n    print(f\"[{round(segment.start, 2)} - {round(segment.end, 2)}]：{text}\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T06:35:30.256282Z","iopub.execute_input":"2023-10-27T06:35:30.256713Z","iopub.status.idle":"2023-10-27T06:36:10.730607Z","shell.execute_reply.started":"2023-10-27T06:35:30.256681Z","shell.execute_reply":"2023-10-27T06:36:10.729342Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Detected language 'zh' with probability 0.988409\n[0.0 - 6.0]：而对面楼是城郊一致作用最大的限购\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#打包models\n!tar -zcvf /kaggle/working/models.tar.gz /kaggle/working/models","metadata":{"execution":{"iopub.status.busy":"2023-10-27T06:39:33.323939Z","iopub.execute_input":"2023-10-27T06:39:33.324406Z","iopub.status.idle":"2023-10-27T06:42:18.914811Z","shell.execute_reply.started":"2023-10-27T06:39:33.324362Z","shell.execute_reply":"2023-10-27T06:42:18.913629Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"tar: Removing leading `/' from member names\n/kaggle/working/models/\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/blobs/\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/blobs/c9074644d9d1205686f16d411564729461324b75\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/blobs/bf2a9746382e1aa7ffff6b3a0d137ed9edbd9670c3b87e5d35f5e85e70d0333a\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/blobs/7818adb6de9fa3064d3ff81226fdd675be1f6344\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/blobs/346bb8684801a61c15ce82bcb80c29a63c2d1f94\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/snapshots/\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/snapshots/f541c54c566e32dc1fbce16f98df699208837e8b/\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/snapshots/f541c54c566e32dc1fbce16f98df699208837e8b/model.bin\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/snapshots/f541c54c566e32dc1fbce16f98df699208837e8b/config.json\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/snapshots/f541c54c566e32dc1fbce16f98df699208837e8b/tokenizer.json\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/snapshots/f541c54c566e32dc1fbce16f98df699208837e8b/vocabulary.txt\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/refs/\n/kaggle/working/models/models--guillaumekln--faster-whisper-large-v2/refs/main\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r\"/kaggle/working/models.tar.gz\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T07:09:35.051600Z","iopub.execute_input":"2023-10-27T07:09:35.052129Z","iopub.status.idle":"2023-10-27T07:09:35.060776Z","shell.execute_reply.started":"2023-10-27T07:09:35.052065Z","shell.execute_reply":"2023-10-27T07:09:35.059553Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/models.tar.gz","text/html":"<a href='/kaggle/working/models.tar.gz' target='_blank'>/kaggle/working/models.tar.gz</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"##4.测试图形界面可行性--需要声卡，不可行","metadata":{}},{"cell_type":"code","source":"import os\nif not os.path.exists(\"/kaggle/working/Whisper-Finetune\"):\n    !git clone https://gitee.com/hohoha/Whisper-Finetune.git /kaggle/working/Whisper-Finetune\n%cd /kaggle/working/Whisper-Finetune\n!git pull \n!pip install -r requirements.txt\n%run ./infer_gui.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##5.下载模型","metadata":{}},{"cell_type":"code","source":"import time\nfrom huggingface_hub import hf_hub_download\nrepo_id = \"guillaumekln/faster-whisper-large-v2\" # 仓库ID\nlocal_dir = '/kaggle/working/models'\ncache_dir = local_dir + \"/cache\"\nfilename= \"config.json\"\nwhile True:   \n    try:\n        hf_hub_download(cache_dir=cache_dir,\n        local_dir=local_dir,\n        repo_id=repo_id,\n        filename=filename,\n        local_dir_use_symlinks=False,\n        resume_download=True,\n        etag_timeout=100\n        )\n    except Exception as e :\n        print(e)\n        # time.sleep(5)\n    else:\n        print('下载完成')\n        break\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}